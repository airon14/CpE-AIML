{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "58033_Lab02_Millicheckers",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/airon14/CpE-AIML/blob/main/58033_Lab02_Millicheckers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUQcd5ApfJM5"
      },
      "source": [
        "# Case 2\n",
        "> **Problem 2.a: Vector Magnitude**\n",
        "\n",
        ">The magnitude of a vector is usually computed as:\n",
        "$$||v|| = \\sqrt{a_0^2 + a_1^2 + ... +a_n^2}$$\n",
        "Whereas $v$ is any vector and $a_k$ are its elements wherein $k$ is the size of $v$.\n",
        "Re-formulate $||v||$ as a function of an inner product. Further discuss this concept and provide your user-defined function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asqQWzJ7gmFv"
      },
      "source": [
        "\n",
        "$||v|| = \\sqrt{v.v}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27RYwjH_fUnO"
      },
      "source": [
        "##Code:\n",
        "def inner_prod(v):\n",
        "  return np.sqrt(v@v)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cH8JpkBj1xS"
      },
      "source": [
        "For the final cases analysis we will be looking at series of equations building up a single feed-forward computation of a logistic regression. The case will not require you to learn fully what is logistic regression. \n",
        "\n",
        "$$X = \\begin{bmatrix} \n",
        "— (x^{(1)})^T— \\\\ \n",
        "— (x^{(2)})^T— \\\\\n",
        "\\vdots \\\\\n",
        "— (x^{(m)})^T— \\\\\n",
        "\\end{bmatrix} \\text{, } \n",
        "Y = \\begin{bmatrix} \n",
        "y^{(1)} \\\\ \n",
        "y^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "y^{(m)} \\\\\n",
        "\\end{bmatrix} \\text{, and } \n",
        "\\theta = \\begin{bmatrix} \n",
        "\\theta^{(1)} \\\\ \n",
        "\\theta^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "\\theta^{(m)} \\\\\n",
        "\\end{bmatrix} $$\n",
        "The dataset $X$ has $m$ entries with $n$ features while $Y$ is the vector containing the groud truths of a the entries of $X$, and $\\theta$ are the parameters or weights of the vectors. We first compute the vector product of the dataset and the parameters as:\n",
        "$$ z = x^{(i)}\\theta^{(i)} = X\\cdot \\theta\\\\_{\\text{Eq. 3.1}}$$\n",
        "We then solve for the hypothesis of the logistic regression alogrithm as:\n",
        "\n",
        "$$ h_\\theta(x) = g(z)\\\\_{\\text{Eq. 3.2}}$$\n",
        "\n",
        "Where $g$ is an acitvation function that maps the values of the hypothesis vector between a range of 0 and 1. We computed the activation as a sigmoid function:\n",
        "$$g(z) = \\frac{1}{1+e^{-z}}\\\\_{\\text{Eq. 3.3}}$$\n",
        "Finally we compute the loss of the logistic regression algorithm using $J$. Wheras $J(\\theta)$ is a function that computes the logistic loss of the hypothesis with respect to the ground truths $y$. it is then computed as:\n",
        "$$J(\\theta) = \\frac{1}{m} \\sum^m_{i=0}=[-y^{(i)}\\log({h_{\\theta}(x^{(i)})})-(1-y^{(i)})\\log(1-h_{\\theta}(x^{(i)}))]\\\\_{\\text{Eq. 3.4}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ8jJV9-qyFy"
      },
      "source": [
        "> **Problem 4.c: Computational Programming (Also Laboratory 2)**\n",
        "\n",
        "> Encode Equations 3.1 to 3.4 as the class `LRegression` wherein:\n",
        "\n",
        "> * `LRegression` should be instantiated with a dataset $X$, a ground truth vector $y$, and a parameter vector $\\theta$. Each parameter should have a data type of `numpy.array`.\n",
        "> * It should further have `methods`reflecting to at least the four (4) aforementioned equations. Each should have a return value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Ex_pXVqsY6"
      },
      "source": [
        "**Problem 4.c: Computational Programming (Also Laboratory 2)**\n",
        "\n",
        "Code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMbCP528CxNO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEG4niqPD1CQ"
      },
      "source": [
        "class Lregression:\n",
        "  def __init__(self, dataset, g_Truth, vect):\n",
        "    self.dataset = dataset\n",
        "    self.g_Truth= g_Truth\n",
        "    self.vect= vect\n",
        "  \n",
        "  def vect_mag(self):\n",
        "    self.mag = np.linalg.norm(self.dataset)\n",
        "    return self.mag\n",
        " \n",
        "  def eq31(self):\n",
        "    self.ans=np.dot(self.dataset.T, self.vect)\n",
        "    return self.ans\n",
        "\n",
        "  def eq33(self):\n",
        "    self.sigmoid = 1/(1+np.exp(-(self.ans)))\n",
        "    return self.sigmoid\n",
        "\n",
        "  def eq34(self):\n",
        "    self.lossLog = np.average(-(self.g_Truth) * np.log(self.vect) - (1-self.g_Truth) * np.log(1 - self.vect))\n",
        "    return self.lossLog\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBG7MiyIOJiI"
      },
      "source": [
        "X = np.random.random((300,5))*100\n",
        "Theta = np.random.random((300,1))\n",
        "Y = np.random.randint(0,2,(300,1))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWWIWOrKOPqu"
      },
      "source": [
        "Regression = Lregression(X, Y, Theta)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mlp_CWXWfls",
        "outputId": "296c313e-21c3-4312-c1c4-631c94b8cdec"
      },
      "source": [
        "Regression.vect_mag()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2273.1953847651293"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXaA_cr-OSRm",
        "outputId": "7e04713a-28f5-47e9-b58d-f8ce863ebac3"
      },
      "source": [
        "Regression.eq31()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7849.62428885],\n",
              "       [7598.15705704],\n",
              "       [7996.04151377],\n",
              "       [7933.21122634],\n",
              "       [7183.0053231 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLTOLWrMOVsi",
        "outputId": "ffb39893-aff4-4205-9472-005ef7040f7d"
      },
      "source": [
        "Regression.eq33()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5SfXV8VOXej",
        "outputId": "419f6c9b-ada2-40d1-d9bc-d1f9fe5febf4"
      },
      "source": [
        "Regression.eq34()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0565547881326354"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}